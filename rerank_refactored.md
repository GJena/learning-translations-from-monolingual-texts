
Should run this file from /export/projects/tto16/users/anni/BLI as that is the directory which has all the dependency files.

HOW TO RUN

python rerank.py language sub_dir config_file

e.g. python rerank.py az withAffixFeatsNoAffixCands_ReTrain /home/ccb/AnnRerankSubDir/rerankll.m3ps.evalonly.config

Note: this will create withAffixFeatsNoAffixCands_ReTrain/az within the cwd with a mkdir -p sub_dir/language command

It takes crawl and wiki data from cwd/<lang>/crawls-minf10 and cwd/<lang>/wiki-minf10. These are generated by babel.

This sub must have the crawls and wikis with both frequency scored and eval data

Also must have burstinessMeasures directory which should have 
1. <dir>/burst.<lang>.<lang> and 
2. <dir>/burst.<lang>.en

and MTurk dictionary 

and depending on if you want to recreate the training and testing files, you want <sub_dir>/<lang>/
1. train.data
2. train.data.index
3. test.data
4. test.data.index

The config file must contain options as mentioned below for the language it is run
Config read:
prefix
prefix candidates
suffix
suffix candidates
do frequency
read/write data
do classification
do logistic regression

If read data, then it reads 4 files in the language crawls sub directory
if do frequency then reads
edit.NUM.scored
time.NUM.scored
aggmrr.NUM.scored
context.NUM.scored
if not then reads
context.scored
time.scored
aggmrr.scored
edit.scored

 Then data of 10 runs is read if if do frequency and readData. These are added to a scores array which should have
crawls context
crawls time
edit
crawls aggmrr
uniq set of words for each freq bin

Then this is for both cases

wiki context
wiki topic
edit
wiki mrr

Then depending on prefix and suffix config, corresponding suffix and prefix scores are also added to the wiki features. It takes english candidates from either prefix or suffix files depending on the config

Then write 1/3 of the data to train, test and blind set

Then run vowpal rabbit with either linear or logistic regression depending on config

After this it computes the accuracies of the predictions and checks if any of the correct answers are in the top sorted candidates or not  

VOWPAL Section

The following can be done about the reviewers’ comments:
1. The vw package has a neural network mode, as well as the option to add quadratic and cubic features automatically. We can test with them individually to check the accuracy.
2. Vowpal also has —l1 and —l2 regularization modes that can help cut down on the feature space. We could try the elastic net and keep very small weights like 0.0001 on both and see how that works.

To run one language based on the model of another language, use crossLangTrainEval.py

Use evalIndFeats.py to evaluate individual features

VW

In the <subdirectory>/<language dir>
We have 
train.data - which is the vowpal wabbit formatted input file. 
<label> | <featurename>:<featurevalue> <featurename>:<featurevalue>…
train.data.index - which is the word representation of the negative and positive samples.
e.g. if you have 
-1 | …
-1 | …
-1 | …
1 | …
this means that the first 3 are negative samples, and in the index they’ll be something like 
bir     inrested        False
bir     mib     False
bir     dougie  False
olan    the     True
which means the first 3 are negative samples of bir not being the 3 words, and olan being the

How the scoring works is that:
1. Vowpal is given training data with positive and negative samples and the feature weights
2. It learns the weights and uses it to predict the scores on the test set, which are basically a line aligned score and fr word - english candidate tuple in the test.predictions and test.data.index respectively. 
3. The test.predictions is read (which has scores only) along with the test.data.index (which is of the form <fr> <en> <answer>). Then a dictionary of the form:
{ 
	fr1 : { en1: score, en2 : score… },
	fr2 : …
} is created
4. The english translations are reverse sorted based on their scores, and then the MTurk seed dictionary is checked to see if the correct english word is present in the english candidates or not
5. The top-k accuracy is then found on this ranked list

OUTPUT

This file generates:
1. if write, <sub_dir>/<lang>/, 
train.data
train.data.index
test.data
test.data.index

2. otherwise will always generate
test.rankcompare
3. will print out
mean reciprocal rank of MRR
mean reciprocal rank of discriminative (ML) method
top1,10 and 100 accuracies for 
